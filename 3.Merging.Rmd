---
title: "Merging data"
author: "Helena Davies"
date: "06/05/2021"
output: html_document
---

Configure global options for all chunks
```{r Setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  comment = '',
  prompt = FALSE,
  cache = FALSE
  )
```

Clear global environment prior to initiation
```{r Clear global environment}
remove(list = ls())
```

Add the add_numeric function - used to convert character variables into numeric variables
Add the remove_duplicates function - used to deduplicate and remove NAs from IDs
Add the sumscores function - used to generate sumscores
Add the package_check function - used to install and load dependencies
Add the imp_check function - used to check variables for implausible values
```{r Read in functions}
source(file = "/Users/helenadavies/werk/ilovedata/scripts/functions/add_numeric.R")
source(file = "/Users/helenadavies/werk/ilovedata/scripts/functions/remove_duplicates.R")
source(file = "/Users/helenadavies/werk/ilovedata/scripts/functions/package_check.R")
source("./functions.R")
```

Use package_check to install and load dependencies
Load tidyverse last
```{r Install load dependencies}
packages <- c("summarytools", "sjlabelled", "Amelia", "gtsummary", "tidyverse")
package_check(packages)
```

Retrieve recent date
We are using the recent date to save files with paste0() as an extension to not overwrite old versions
```{r Recent date}
date <- Sys.Date()
date
```

# Import all baseline data (generated from the preprocessing script)
+++HLD: NEED TO UPDATE
```{r Read in baseline data of all datasets}
glad_baseline <- readRDS(file = "../data_cleaned/BASELINE_glad2021-07-21.rds")
dim(glad_baseline)

edgi_baseline <- readRDS(file = "../data_cleaned/BASELINE_edgi2021-07-21.rds")
dim(edgi_baseline)

nbr_baseline <- readRDS(file = "../data_cleaned/BASELINE_nbr2021-07-21.rds")
dim(nbr_baseline)

ramp_baseline <- readRDS(file = "../data_cleaned/BASELINE_ramp2021-07-21.rds")
dim(ramp_baseline)
```

Rename columns to be consistent across all datasets
```{r Rename columns for consistency}
# Age called "age_unc" in RAMP
ramp_baseline <- ramp_baseline %>% 
  rename(
    age_category = age_unc,
    )
```

# Merge all baseline data
```{r Merge all baseline data}
# Bind all baseline data
baseline_data <- bind_rows(
  glad_baseline,
  edgi_baseline,
  nbr_baseline,
  ramp_baseline
)

# Check
colnames(baseline_data)
nrow(baseline_data)

```

# Merging of follow up data
## Import follow up data
+++HLD: NEED TO UPDATE!
```{r Read in data follow up all datasets}

taf_ramp <- readRDS(file = "../data_cleaned/TAF_ramp2021-06-29.rds")
dim(taf_ramp)

taf_coping <- readRDS(file = "../data_cleaned/TAF_coping2021-06-29.rds")
dim(taf_coping)

edeq_coping_screener <- readRDS(file = "../data_cleaned/EDEQ_screener_coping2021-06-29.rds")
dim(edeq_coping_screener)

edeq_ramp_screener <- readRDS(file = "../data_cleaned/EDEQ_screener_ramp2021-06-29.rds")
dim(edeq_ramp_screener)

virus_ramp <- readRDS(file = "../data_cleaned/VIRUS_ramp_followup2021-06-29.rds")
dim(virus_ramp)
  
virus_coping <- readRDS(file = "../data_cleaned/VIRUS_coping_followup2021-06-29.rds")
dim(virus_coping)

loss_ramp <- readRDS(file = "../data_cleaned/LOSS_ramp_followup2021-06-29.rds")
dim(loss_ramp)

loss_coping <- readRDS(file = "../data_cleaned/LOSS_coping_followup2021-06-29.rds")
dim(loss_coping)

dem_coping_followup <- readRDS(file = "../data_cleaned/DEM_followup_coping2021-06-29.rds")
dim(dem_coping_followup)

dem_ramp_followup <- readRDS(file = "../data_cleaned/DEM_followup_ramp2021-06-29.rds")
dim(dem_ramp_followup)

resp_coping_followup <- readRDS(file = "../data_cleaned/RESP_coping_followup2021-07-21.rds")
dim(resp_coping_followup)

resp_ramp_followup <- readRDS(file = "../data_cleaned/RESP_ramp_followup2021-07-21.rds")
dim(resp_ramp_followup)
```

Bind EDEQ from COPING & RAMP together
```{r Bind EDEQ and TAF COPING and RAMP}
# Bind all EDEQ data
EDEQ <- bind_rows(edeq_ramp_screener,
                 edeq_coping_screener)


# Check
colnames(EDEQ)
nrow(EDEQ)

```

Bind TAF from COPING & RAMP together
```{r}
# Bind all TAF data
TAF <- bind_rows(taf_ramp,
                 taf_coping)

# Check
colnames(TAF)
nrow(TAF)
```

Bind VIRUS data from RAMP & COPING
```{r Bind VIRUS data COPING and RAMP}
VIRUS <- bind_rows(virus_ramp,
                 virus_coping)


# Check 
colnames(VIRUS)
nrow(VIRUS)
```

Bind LOSS data from RAMP & COPING
```{r Bind LOSS data RAMP & COPING}
LOSS <- bind_rows(loss_ramp,
                 loss_coping)


# Check
colnames(LOSS)
nrow(LOSS)
```

Bind RESP follow up data from RAMP & COPING
```{r Bind RESP follow up data RAMP & COPING}
RESP <- bind_rows(resp_coping_followup,
                 resp_ramp_followup)


# Check
colnames(RESP)
nrow(RESP)
```

Bind DEM follow up data from RAMP & COPING
```{r Bind DEM follow up data RAMP & COPING}
DEM_FOLLOWUP <- bind_rows(dem_ramp_followup,
                 dem_coping_followup)


# Check
colnames(DEM_FOLLOWUP)
nrow(DEM_FOLLOWUP)
```

# Read in data
## EDGI, RAMP, GLAD & NBR
### ED baseline grouping data (generated from the script "2.BASELINE_ED_groupings")
```{r Read in ED data ED grouping}
baseline_ED_groups_data <- readRDS(file = "../data_cleaned/ED_BASELINE_groups2021-10-20.rds")

# Check
colnames(baseline_ED_groups_data)
nrow(baseline_ED_groups_data)
```
# Read in data
## EDGI, RAMP, GLAD & NBR
### OCD screener data
```{r Read in ED data ED grouping}
OCD_screener <- readRDS(file = "../data_cleaned/OCD_screener2021-10-20.rds")

# Check
colnames(OCD_screener)
nrow(OCD_screener)
```

# Final merge of all baseline and follow up data
## Merge all follow up data and ED baseline groupings
```{r Merge all follow up data and ED baseline groupings}
dfs.list <- list(DEM_FOLLOWUP,
                 LOSS,
                 RESP,
                 VIRUS,
                 TAF,
                 EDEQ,
                 baseline_ED_groups_data,
                 OCD_screener) # Will leave out for now as an optional questionnaire so will lose some participants, can add later

follow_up_data <- plyr::join_all(
  dfs.list,
  by = "ID"
  )

# Check
colnames(follow_up_data)
nrow(follow_up_data)
```
*Temporary solution - need to go back and edit / re-run preprocessing script
Cohort names do not match across datasets. Need to re-name before merging.
```{r Temporary solution, renaming cohort names before merging}

follow_up_data <- follow_up_data %>%
  mutate(cohort_name =
           case_when(
             cohort_name == "coping_glad" ~ "coping_glad",
             is.na(cohort_name)  ~ "coping_edgi",
             cohort_name == "coping_nbr" ~ "nbr",
             cohort_name == "ramp" ~ "ramp"
           ))

```

Merge follow up data with baseline data 
```{r Merge follow up data with baseline data}
dfs.list <- list(baseline_data,
                 follow_up_data)

data.final <- plyr::join_all(
  dfs.list,
  by = c("ID",
         "cohort_name")
  )

# Check
colnames(data.final)
nrow(data.final)

```

Remove duplicate IDs 
```{r Remove duplicate IDs from final dataset}
# As each phase is now a column, there should be NO dup IDs
data.final.no.dup  <- data.final  %>%
  filter(., !duplicated(ID)) 

# Check 
nrow(data.final)
```

Check final data
```{r Skim final data with no dup IDs}
# Look at the data
skimr::skim(data.final.no.dup)
```

Save final dataset
```{r Save final dataset}
saveRDS(object = data.final.no.dup,
        file = paste0("/Users/helenadavies/werk/EDBEHSELFHARM2/gitEDBEHSELFHARM/data_cleaned/dat_merged", date, ".rds"))

```



